{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2 - Baseline Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train a TFIDF with Naive Bayes Baseline Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd \r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "# Check out our training\r\n",
    "df = pd.read_csv(\"./Data/Train.csv\")\r\n",
    "test_df = pd.read_csv(\"./Data/Test.csv\")\r\n",
    "\r\n",
    "## TODO: We need to split the training data into train and dev, since we will be doing some hyper parameter optimization\r\n",
    "## but we know from our data exploration that our data is skewed. \r\n",
    "## We want to do stratified selection to ensure that each class is represented in the dev set\r\n",
    "\r\n",
    "## <your code here>"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## TODO: Train a TF-IDF with Naive Bayes Baseline Model, using sklearn\r\n",
    "\r\n",
    "## <Your code here>"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## TODO: Report the accuracy, log loss, and macro and micro F1 Scores. \r\n",
    "\r\n",
    "## <Your code here>"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis\n",
    "\n",
    "According to our Macro F1 Score compared to our Micro F1 Score, we're likely not doing well when classifying the minority classes. Let's do a bit of hyper parameter optimization to see if we can improve our result at all"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyper Parameter Optimization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GridSearchCV\r\n",
    "\r\n",
    "## TODO: Let's do a grid search optimization \r\n",
    "\r\n",
    "# <your code here>"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Report on accuracy, log loss and macro and micro F1 score. \r\n",
    "\r\n",
    "# <your code here>"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis\r\n",
    "\r\n",
    "Analyze the effects of hyper parameter optimization. Did it improve? Did it get worse?\r\n",
    "\r\n",
    "<TODO: Write Your Answer Here> "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Error Analysis\r\n",
    "\r\n",
    "To understand more about the problems of our model, we need to do some error analysis!\r\n",
    "\r\n",
    "Error analysis typically involves looking at the misclassifications of the model. We typically inspect the dev set."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Let's look at the misclassifications\r\n",
    "\r\n",
    "# <TODO: Output a graph which will show how the target classes were misclassified. "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis\r\n",
    "\r\n",
    "1. Is the model performing poorly on any classes?\r\n",
    "2. Given the model we're using, why is that the case? \r\n",
    "\r\n",
    "TODO: Your answers here. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: Take a look at the worst performing category and see what it's getting misclassified as. \r\n",
    "\r\n",
    "# <Your code here to output some samples>, the predicted category and the correct target category "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis\r\n",
    "\r\n",
    "1. Provide a possible reason why that misclassification is occuring.\r\n",
    "2. What recommendations would give as possible next steps for improving performance on this model? "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: Save your results in a csv called results.csv"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('kalido': virtualenvwrapper)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "a3ec8f5d450910ae9e345d2d6b71e2a1cdfe39f783d83bbc796650da91e67631"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}